{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b8e60e-1874-4dea-a5ad-414a3a3adaba",
   "metadata": {},
   "source": [
    "__Note: See requirements.txt for dependencies.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79597d0c-a320-4486-b0ea-7a914cb9ced4",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b42bbb-fcf5-4975-a4b1-6703e720de87",
   "metadata": {},
   "source": [
    "`python -m prodigy train --textcat-multilabel hmwk2-train-final,eval:hmwk2-eval-final ./experiment-1`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dab4643f-8d7d-4faf-ad1d-aa99d9012d58",
   "metadata": {},
   "source": [
    "ℹ Using CPU\n",
    "\n",
    "========================= Generating Prodigy config =========================\n",
    "ℹ Auto-generating config with spaCy\n",
    "✔ Generated training config\n",
    "\n",
    "=========================== Initializing pipeline ===========================\n",
    "[2024-03-19 21:52:51,459] [INFO] Set up nlp object from config\n",
    "Components: textcat_multilabel\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [textcat_multilabel] Training: 1018 | Evaluation: 199 (from datasets)\n",
    "Training: 1018 | Evaluation: 199\n",
    "Labels: textcat_multilabel (2)\n",
    "[2024-03-19 21:52:51,617] [INFO] Pipeline: ['textcat_multilabel']\n",
    "[2024-03-19 21:52:51,621] [INFO] Created vocabulary\n",
    "[2024-03-19 21:52:51,622] [INFO] Finished initializing nlp object\n",
    "[2024-03-19 21:52:52,948] [INFO] Initialized pipeline components: ['textcat_multilabel']\n",
    "✔ Initialized pipeline\n",
    "\n",
    "============================= Training pipeline =============================\n",
    "Components: textcat_multilabel\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [textcat_multilabel] Training: 1018 | Evaluation: 199 (from datasets)\n",
    "Training: 1018 | Evaluation: 199\n",
    "Labels: textcat_multilabel (2)\n",
    "ℹ Pipeline: ['textcat_multilabel']\n",
    "ℹ Initial learn rate: 0.001\n",
    "E    #       LOSS TEXTC...  CATS_SCORE  SCORE\n",
    "---  ------  -------------  ----------  ------\n",
    "  0       0           0.25       24.84    0.25\n",
    "  0     200          45.92       74.28    0.74\n",
    "  1     400          39.62       82.05    0.82\n",
    "  1     600          27.48       84.43    0.84\n",
    "  2     800          21.09       82.97    0.83\n",
    "  3    1000          18.05       86.23    0.86\n",
    "  4    1200          13.32       85.93    0.86\n",
    "  5    1400          11.29       85.16    0.85\n",
    "  7    1600           8.74       84.59    0.85\n",
    "  9    1800           7.07       85.05    0.85\n",
    " 12    2000           5.24       85.33    0.85\n",
    " 15    2200           4.00       84.97    0.85\n",
    " 19    2400           2.97       85.16    0.85\n",
    " 23    2600           2.41       85.00    0.85\n",
    "✔ Saved pipeline to output directory\n",
    "experiment-1/model-last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b53dc-bb3b-45e3-8a06-1a3e907c5fff",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a6b99-9895-42df-b1c4-46047cf8770b",
   "metadata": {},
   "source": [
    "`python -m prodigy data-to-spacy --textcat-multilabel hmwk2-train-final,eval:hmwk2-eval-final ./corpus --base-model en_core_web_md`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5479a6d1-779c-432a-9850-a8bf29c7b35d",
   "metadata": {},
   "source": [
    "ℹ Using base model 'en_core_web_md'\n",
    "\n",
    "============================== Generating data ==============================\n",
    "Components: textcat_multilabel\n",
    "Merging training and evaluation data for 1 components\n",
    "  - [textcat_multilabel] Training: 1018 | Evaluation: 199 (from datasets)\n",
    "Training: 1018 | Evaluation: 199\n",
    "Labels: textcat_multilabel (2)\n",
    "✔ Saved 1018 training examples\n",
    "corpus/train.spacy\n",
    "✔ Saved 199 evaluation examples\n",
    "corpus/dev.spacy\n",
    "\n",
    "============================= Generating config =============================\n",
    "ℹ Auto-generating config with spaCy\n",
    "ℹ Using config from base model\n",
    "✔ Generated training config\n",
    "\n",
    "======================== Generating cached label data ========================\n",
    "✔ Saving label data for component 'tagger'\n",
    "corpus/labels/tagger.json\n",
    "✔ Saving label data for component 'parser'\n",
    "corpus/labels/parser.json\n",
    "✔ Saving label data for component 'ner'\n",
    "corpus/labels/ner.json\n",
    "✔ Saving label data for component 'textcat_multilabel'\n",
    "corpus/labels/textcat_multilabel.json\n",
    "\n",
    "============================= Finalizing export =============================\n",
    "✔ Saved training config\n",
    "corpus/config.cfg\n",
    "\n",
    "To use this data for training with spaCy, you can run:\n",
    "python -m spacy train corpus/config.cfg --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eafc18-9bcd-449e-8617-e4f803238345",
   "metadata": {},
   "source": [
    "`python -m spacy train corpus/config.cfg --paths.train corpus/train.spacy\n",
    "--paths.dev corpus/dev.spacy --output ./experiment-2`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b80fe431-384e-4b94-91ac-998879f2817b",
   "metadata": {},
   "source": [
    "✔ Created output directory: experiment-2\n",
    "ℹ Saving to output directory: experiment-2\n",
    "ℹ Using CPU\n",
    "\n",
    "=========================== Initializing pipeline ===========================\n",
    "✔ Initialized pipeline\n",
    "\n",
    "============================= Training pipeline =============================\n",
    "ℹ Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler',\n",
    "'lemmatizer', 'ner', 'textcat_multilabel']\n",
    "ℹ Frozen components: ['tagger', 'parser', 'attribute_ruler',\n",
    "'lemmatizer', 'ner']\n",
    "ℹ Initial learn rate: 0.001\n",
    "E    #       LOSS TOK2VEC  LOSS TEXTC...  CATS_SCORE  SPEED   SCORE\n",
    "---  ------  ------------  -------------  ----------  ------  ------\n",
    "  0       0          0.14           0.32       47.34  5236.03    0.47\n",
    "  3    1000         55.19         152.56       88.52  5583.55    0.89\n",
    " 12    2000         84.92          15.01       87.72  4891.91    0.88\n",
    " 32    3000        119.86           4.19       88.54  5094.89    0.89\n",
    " 53    4000        124.70           4.04       88.55  4932.96    0.89\n",
    " 74    5000         72.70           2.93       88.52  5194.05    0.89\n",
    " 96    6000         55.39           3.06       88.25  5505.77    0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9ecea-b3e2-49c1-a492-1ab075447068",
   "metadata": {},
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874170c3-21df-4c82-9580-5ef2243187e5",
   "metadata": {},
   "source": [
    "`pip install \"prodigy-hf @git+https://github.com/explosion/prodigy-hf\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a3ed3-575a-4914-af31-9b5a441a1d1f",
   "metadata": {},
   "source": [
    "`python -m prodigy hf.train.textcat hmwk2-train-final,eval:hmwk2-eval-fina\n",
    "l ./experiment-3 --epochs 10 --model-name \"distilbert-base-uncased\" --verbose`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "710ff456-ed04-4853-8b60-53f7e05106d3",
   "metadata": {},
   "source": [
    "tokenizer_config.json: 100%|█████████████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 64.7kB/s]\n",
    "config.json: 100%|█████████████████████████████████████████████████████████████████████| 483/483 [00:00<00:00, 2.45MB/s]\n",
    "vocab.txt: 100%|█████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 3.76MB/s]\n",
    "tokenizer.json: 100%|████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 6.73MB/s]\n",
    "Map: 100%|█████████████████████████████████████████████████████████████████| 1016/1016 [00:01<00:00, 1006.67 examples/s]\n",
    "Map: 100%|███████████████████████████████████████████████████████████████████| 199/199 [00:00<00:00, 5064.91 examples/s]\n",
    "model.safetensors: 100%|█████████████████████████████████████████████████████████████| 268M/268M [00:28<00:00, 9.40MB/s]\n",
    "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "Downloading builder script: 100%|██████████████████████████████████████████████████| 4.20k/4.20k [00:00<00:00, 12.2MB/s]\n",
    "/home/ephann/homework2/hw2_venv/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:\n",
    "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
    "  warnings.warn(\n",
    "  0%|                                                                               | 1/1270 [00:53<18:48:59, 53.38s/it]\n",
    "Killed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
